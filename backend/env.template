# MarkDown OCR Configuration Template
# Copy this file to .env and customize as needed

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# Active LLM Provider: "ollama" or "lm_studio"
LLM_PROVIDER=ollama

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434/v1

# LM Studio Configuration
LM_STUDIO_BASE_URL=http://localhost:1234/v1

# Text Model (for text-only processing or fallback)
# Examples: llama3, mistral, codellama
LLM_MODEL=llama3

# ============================================================================
# Vision Model Configuration (Enhanced Feature)
# ============================================================================

# Enable vision model processing (true/false)
# true: Process PDF pages as images for better accuracy (recommended)
# false: Use text extraction only (faster but less accurate)
USE_VISION_MODEL=true

# Vision Model Name
# Ollama examples: llava, llava:13b, llava:34b, bakllava
# LM Studio: Use any vision-capable model loaded in LM Studio
VISION_MODEL=llava

# PDF Rendering Quality (DPI)
# Lower values = faster processing, lower quality
# Higher values = slower processing, better quality
# Recommended values:
#   100 = Fast, readable text
#   150 = Balanced (recommended)
#   200 = High quality
#   300 = Maximum quality (very slow)
PDF_DPI=150

# Image Format: "png" or "jpeg"
# PNG: Better quality, larger files, slower
# JPEG: Faster, smaller files, slight quality loss
IMAGE_FORMAT=png

# ============================================================================
# Application Settings
# ============================================================================

# Project Name
PROJECT_NAME=MarkDown OCR

# API Version
API_V1_STR=/api/v1

# Storage Directories (relative to backend/)
UPLOAD_DIR=uploads
OUTPUT_DIR=outputs

# ============================================================================
# CORS Configuration
# ============================================================================

# Allowed origins (comma-separated)
# Use "*" for development, specific domains for production
CORS_ORIGINS=*

# ============================================================================
# Docker-Specific Settings
# ============================================================================

# When running in Docker, use host.docker.internal instead of localhost
# Uncomment the lines below for Docker deployment:

# OLLAMA_BASE_URL=http://host.docker.internal:11434/v1
# LM_STUDIO_BASE_URL=http://host.docker.internal:1234/v1

# For Linux Docker, use 172.17.0.1 instead:
# OLLAMA_BASE_URL=http://172.17.0.1:11434/v1
# LM_STUDIO_BASE_URL=http://172.17.0.1:1234/v1

# ============================================================================
# Performance Tuning Tips
# ============================================================================

# For faster processing (lower quality):
# USE_VISION_MODEL=false
# PDF_DPI=100
# IMAGE_FORMAT=jpeg

# For best quality (slower):
# USE_VISION_MODEL=true
# VISION_MODEL=llava:13b
# PDF_DPI=200
# IMAGE_FORMAT=png

# For scanned documents or complex layouts:
# USE_VISION_MODEL=true
# VISION_MODEL=llava:13b
# PDF_DPI=200
# IMAGE_FORMAT=png

# For simple text documents:
# USE_VISION_MODEL=false
# LLM_MODEL=llama3
